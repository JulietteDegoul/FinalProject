{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582308e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f40acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indie_df = pd.read_csv('Data/indiegogo_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b06f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create target value column, based on funded_percent\n",
    "indie_df['funded_percent'] = indie_df['funded_percent'].str.replace('%', '').astype(float)\n",
    "indie_df['is_success'] = (indie_df['funded_percent'] >= 80).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b48cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add day of the week column, based on launch date\n",
    "from datetime import datetime\n",
    "indie_df['date_launch'] = pd.to_datetime(indie_df['date_launch'])\n",
    "day_names = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "indie_df['day_of_week'] = indie_df['date_launch'].apply(lambda x: day_names[x.weekday()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummifying \n",
    "day_dummies = pd.get_dummies(indie_df['day_of_week'])\n",
    "indie_df = pd.concat([indie_df, day_dummies], axis=1)\n",
    "indie_df.columns = indie_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b454a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indie_df = pd.to_csv('Data/indiepygo_ready.csv') #save pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d81c0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/IndiePyGo_nulldropped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e568eda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tagline</th>\n",
       "      <th>is_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Join the Electric Revolution!!!</td>\n",
       "      <td>Pure electric motorcycle proves a powerful alt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Relief Trip to Haiti</td>\n",
       "      <td>Send Me to Haiti...I'm needed there!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Out To Reach Leogane, Haiti 2010</td>\n",
       "      <td>Haiti Relief Mission to Leogane</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Transpersonal Papers: 1861-2010</td>\n",
       "      <td>My third book on Fezziwig Press.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homeless Veterans need a Hand UP not Hand Out!</td>\n",
       "      <td>Homeless Veterans Transitional Housing Develop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20613</th>\n",
       "      <td>Totally Gay Productions</td>\n",
       "      <td>Trans filmmaker making queer documentaries. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20614</th>\n",
       "      <td>Lady Crow debut EP</td>\n",
       "      <td>Help us finance Every Stone, our first EP!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20615</th>\n",
       "      <td>JOSA, the ultimate Venice-Inspired bracelet</td>\n",
       "      <td>Benefits Save Venice, helps to protect Venice'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20616</th>\n",
       "      <td>My Campaign Title</td>\n",
       "      <td>Hi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20617</th>\n",
       "      <td>My Campaign Title</td>\n",
       "      <td>Hi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20618 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                     Join the Electric Revolution!!!   \n",
       "1                                Relief Trip to Haiti   \n",
       "2                    Out To Reach Leogane, Haiti 2010   \n",
       "3                 The Transpersonal Papers: 1861-2010   \n",
       "4      Homeless Veterans need a Hand UP not Hand Out!   \n",
       "...                                               ...   \n",
       "20613                         Totally Gay Productions   \n",
       "20614                              Lady Crow debut EP   \n",
       "20615     JOSA, the ultimate Venice-Inspired bracelet   \n",
       "20616                               My Campaign Title   \n",
       "20617                               My Campaign Title   \n",
       "\n",
       "                                                 tagline  is_success  \n",
       "0      Pure electric motorcycle proves a powerful alt...           0  \n",
       "1                  Send Me to Haiti...I'm needed there!            0  \n",
       "2                        Haiti Relief Mission to Leogane           0  \n",
       "3                       My third book on Fezziwig Press.           0  \n",
       "4      Homeless Veterans Transitional Housing Develop...           0  \n",
       "...                                                  ...         ...  \n",
       "20613  Trans filmmaker making queer documentaries. It...           0  \n",
       "20614         Help us finance Every Stone, our first EP!           0  \n",
       "20615  Benefits Save Venice, helps to protect Venice'...           0  \n",
       "20616                                                 Hi           0  \n",
       "20617                                                 Hi           0  \n",
       "\n",
       "[20618 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indie_text_df = df[['title', 'tagline', 'is_success']]\n",
    "indie_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61b2e173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/t2vz9kkn6z99y7p0rnwcq33m0000gn/T/ipykernel_64180/2641864021.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  indie_text_df['text'] = indie_text_df['title'] + ' ' + indie_text_df['tagline']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        Join the Electric Revolution!!! Pure electric ...\n",
       "1        Relief Trip to Haiti Send Me to Haiti...I'm ne...\n",
       "2        Out To Reach Leogane, Haiti 2010 Haiti Relief ...\n",
       "3        The Transpersonal Papers: 1861-2010 My third b...\n",
       "4        Homeless Veterans need a Hand UP not Hand Out!...\n",
       "                               ...                        \n",
       "20613    Totally Gay Productions Trans filmmaker making...\n",
       "20614    Lady Crow debut EP Help us finance Every Stone...\n",
       "20615    JOSA, the ultimate Venice-Inspired bracelet Be...\n",
       "20616                                 My Campaign Title Hi\n",
       "20617                                 My Campaign Title Hi\n",
       "Name: text, Length: 20618, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indie_text_df['text'] = indie_text_df['title'] + ' ' + indie_text_df['tagline']\n",
    "indie_text_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a57432d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/t2vz9kkn6z99y7p0rnwcq33m0000gn/T/ipykernel_64180/2395777452.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  indie_text_df.drop(['title', 'tagline'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "indie_text_df.drop(['title', 'tagline'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283662c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fb3e55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_success</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Join the Electric Revolution!!! Pure electric ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Relief Trip to Haiti Send Me to Haiti...I'm ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Out To Reach Leogane, Haiti 2010 Haiti Relief ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The Transpersonal Papers: 1861-2010 My third b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Homeless Veterans need a Hand UP not Hand Out!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20613</th>\n",
       "      <td>0</td>\n",
       "      <td>Totally Gay Productions Trans filmmaker making...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20614</th>\n",
       "      <td>0</td>\n",
       "      <td>Lady Crow debut EP Help us finance Every Stone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20615</th>\n",
       "      <td>0</td>\n",
       "      <td>JOSA, the ultimate Venice-Inspired bracelet Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20616</th>\n",
       "      <td>0</td>\n",
       "      <td>My Campaign Title Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20617</th>\n",
       "      <td>0</td>\n",
       "      <td>My Campaign Title Hi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20618 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_success                                               text\n",
       "0               0  Join the Electric Revolution!!! Pure electric ...\n",
       "1               0  Relief Trip to Haiti Send Me to Haiti...I'm ne...\n",
       "2               0  Out To Reach Leogane, Haiti 2010 Haiti Relief ...\n",
       "3               0  The Transpersonal Papers: 1861-2010 My third b...\n",
       "4               0  Homeless Veterans need a Hand UP not Hand Out!...\n",
       "...           ...                                                ...\n",
       "20613           0  Totally Gay Productions Trans filmmaker making...\n",
       "20614           0  Lady Crow debut EP Help us finance Every Stone...\n",
       "20615           0  JOSA, the ultimate Venice-Inspired bracelet Be...\n",
       "20616           0                               My Campaign Title Hi\n",
       "20617           0                               My Campaign Title Hi\n",
       "\n",
       "[20618 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indie_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acdc9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "indie_text_df.to_csv('indiepygo_text_fornlp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8de9f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    indie_text_df.text, \n",
    "    indie_text_df.is_success, \n",
    "    test_size=0.2, \n",
    "    random_state=2022,\n",
    "    stratify=indie_text_df.is_success\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8748a9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12826\n",
       "1     3668\n",
       "Name: is_success, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cae59aae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3207\n",
       "1     917\n",
       "Name: is_success, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b635aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e6c734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88      3207\n",
      "           1       0.66      0.12      0.21       917\n",
      "\n",
      "    accuracy                           0.79      4124\n",
      "   macro avg       0.73      0.55      0.54      4124\n",
      "weighted avg       0.77      0.79      0.73      4124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e45af3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88      3207\n",
      "           1       0.76      0.06      0.11       917\n",
      "\n",
      "    accuracy                           0.79      4124\n",
      "   macro avg       0.77      0.53      0.50      4124\n",
      "weighted avg       0.78      0.79      0.71      4124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40657462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      3207\n",
      "           1       0.79      0.03      0.06       917\n",
      "\n",
      "    accuracy                           0.78      4124\n",
      "   macro avg       0.79      0.51      0.47      4124\n",
      "weighted avg       0.79      0.78      0.69      4124\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliettedegoul/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('KNN', KNeighborsClassifier())         \n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc5db9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/t2vz9kkn6z99y7p0rnwcq33m0000gn/T/ipykernel_64180/2820257893.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  indie_text_df['text'] = indie_text_df['text'].str.lower()\n",
      "/var/folders/mh/t2vz9kkn6z99y7p0rnwcq33m0000gn/T/ipykernel_64180/2820257893.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  indie_text_df['text'] = indie_text_df['text'].str.replace('[^\\w\\s]','')\n",
      "/var/folders/mh/t2vz9kkn6z99y7p0rnwcq33m0000gn/T/ipykernel_64180/2820257893.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  indie_text_df['text'] = indie_text_df['text'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "indie_text_df['text'] = indie_text_df['text'].str.lower()\n",
    "indie_text_df['text'] = indie_text_df['text'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1adb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juliettedegoul/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/mh/t2vz9kkn6z99y7p0rnwcq33m0000gn/T/ipykernel_64180/2816505140.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  indie_text_df['text'] = indie_text_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "indie_text_df['text'] = indie_text_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4a38a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    indie_text_df.text, \n",
    "    indie_text_df.is_success, \n",
    "    test_size=0.2, \n",
    "    random_state=2022,\n",
    "    stratify=indie_text_df.is_success\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cdc2523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88      3207\n",
      "           1       0.66      0.16      0.26       917\n",
      "\n",
      "    accuracy                           0.79      4124\n",
      "   macro avg       0.73      0.57      0.57      4124\n",
      "weighted avg       0.77      0.79      0.74      4124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b637063b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'Word2Vec(vocab=425, vector_size=100, alpha=0.025)' (type <class 'gensim.models.word2vec.Word2Vec'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mh/t2vz9kkn6z99y7p0rnwcq33m0000gn/T/ipykernel_64180/2052500781.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m clf = Pipeline([\n\u001b[0m\u001b[1;32m      6\u001b[0m      \u001b[0;34m(\u001b[0m\u001b[0;34m'Word2Vec'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindie_text_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m      \u001b[0;34m(\u001b[0m\u001b[0;34m'Random Forest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transform\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             ):\n\u001b[0;32m--> 207\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    208\u001b[0m                     \u001b[0;34m\"All intermediate steps should be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0;34m\"transformers and implement fit and transform \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'Word2Vec(vocab=425, vector_size=100, alpha=0.025)' (type <class 'gensim.models.word2vec.Word2Vec'>) doesn't"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('Word2Vec',Word2Vec(sentences=indie_text_df['text'], vector_size=100, window=5, min_count=1, workers=4)),    \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42832e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(w2v_model, sentence):\n",
    "    \"\"\"\n",
    "    Compute the sentence embedding using the average of word embeddings.\n",
    "    \"\"\"\n",
    "    words = sentence.split()\n",
    "    words_vectors = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vectors) == 0:\n",
    "        return np.zeros(w2v_model.vector_size)\n",
    "    else:\n",
    "        return np.mean(words_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99691b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      3207\n",
      "           1       0.48      0.04      0.07       917\n",
      "\n",
      "    accuracy                           0.78      4124\n",
      "   macro avg       0.63      0.51      0.47      4124\n",
      "weighted avg       0.72      0.78      0.70      4124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(indie_text_df['text'], indie_text_df['is_success'], test_size=0.2, random_state=42, stratify=indie_text_df['is_success'])\n",
    "\n",
    "# Train Word2Vec\n",
    "w2v_model = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Transform the text data to embeddings\n",
    "X_train_embeddings = [get_sentence_embedding(w2v_model, sentence) for sentence in X_train]\n",
    "X_test_embeddings = [get_sentence_embedding(w2v_model, sentence) for sentence in X_test]\n",
    "\n",
    "# Fit the random forest model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf.predict(X_test_embeddings)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b0943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
